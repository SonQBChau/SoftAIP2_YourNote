{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\zhang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Loved the new owners of this spot! The minute ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My son and I took a trip out to Phoenix Herpet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Had a horrible experence with the lash extensi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I love this place. Everything is so fresh and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Very average pho joint. Nothing particularly s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Loved the new owners of this spot! The minute ...\n",
       "1  My son and I took a trip out to Phoenix Herpet...\n",
       "2  Had a horrible experence with the lash extensi...\n",
       "3  I love this place. Everything is so fresh and ...\n",
       "4  Very average pho joint. Nothing particularly s..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt') # one time execution\n",
    "import re\n",
    "cols = ['business_id','cool','date','funny','review_id','stars','useful','user_id']\n",
    "path ='D:\\s8.json'\n",
    "df = pd.read_json(path)\n",
    "df = df.drop(cols,axis=1) \n",
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Loved the new owners of this spot! The minute we walked in we were greeted and very friendly. The rooms have still not been upgraded, but we saw the renovations being planned and I cannot wait to come back! The rooms were still very comfortable and had a great view. We ate at the restaurant for brunch and dinner and it did not disappoint. The waiters were very friendly and well priced. Food was very flavorful, I highly recommend the scallops!  The front desk staff is very helpful and so nice. It's refreshing to get out of vegas and experience this. I cannot wait to come back, the location is beautiful!\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b64d7b58bcf7419da778a5b52bec98e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='progress bar', max=21122, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "174938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Loved the new owners of this spot!',\n",
       " 'The minute we walked in we were greeted and very friendly.',\n",
       " 'The rooms have still not been upgraded, but we saw the renovations being planned and I cannot wait to come back!',\n",
       " 'The rooms were still very comfortable and had a great view.',\n",
       " 'We ate at the restaurant for brunch and dinner and it did not disappoint.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate a single summary for all the texts\n",
    "# 1. Split Text into Sentences\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from tqdm import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "sentences = []\n",
    "for s in tqdm(df['text'], desc = 'progress bar', leave=True):\n",
    "  sentences.append(sent_tokenize(s))\n",
    "sentences = [y for x in sentences for y in x] # flatten list\n",
    "print(len(sentences))\n",
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d348e7ff2f4e1fbd5a328845fb1ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='progress bar', max=1, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract word vectors\n",
    "word_embeddings = {}\n",
    "path1 = 'E:\\word_embedding\\glove_100d.txt'\n",
    "f = open(path1, encoding='utf-8')\n",
    "for line in tqdm(f, desc = 'progress bar', leave=True):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    word_embeddings[word] = coefs\n",
    "f.close()\n",
    "len(word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zhang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['loved new owners spot',\n",
       " 'minute walked greeted friendly',\n",
       " 'rooms still upgraded saw renovations planned cannot wait come back',\n",
       " 'rooms still comfortable great view',\n",
       " 'ate restaurant brunch dinner disappoint']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Text Preprocessing\n",
    "# remove punctuations, numbers and special characters\n",
    "clean_sentences = pd.Series(sentences).str.replace(\"[^a-zA-Z]\", \" \")\n",
    "# make alphabets lowercase\n",
    "clean_sentences = [s.lower() for s in clean_sentences]\n",
    "#Get rid of the stopwords\n",
    "nltk.download('stopwords')\n",
    "# import the stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "# define a function to remove stopwords\n",
    "def remove_stopwords(sen):\n",
    "    sen_new = \" \".join([i for i in sen if i not in stop_words])\n",
    "    return sen_new\n",
    "# remove stopwords from the sentences\n",
    "clean_sentences = [remove_stopwords(r.split()) for r in clean_sentences]\n",
    "clean_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "256d7f46051a4b6897923c9f51068045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='progress bar', max=174938, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.01573185,  0.19939011,  0.514905  , -0.3805214 ,  0.01422596],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use clean_sentences to create vectors for sentences in data using the GloVe word vectors\n",
    "# Extract word vectors\n",
    "\n",
    "sentence_vectors = []\n",
    "for i in tqdm(clean_sentences, desc = 'progress bar', leave=True):\n",
    "    if len(i) != 0:\n",
    "        v = sum([word_embeddings.get(w, np.zeros((100,))) for w in i.split()])/(len(i.split())+0.001)\n",
    "    else:\n",
    "        v = np.zeros((100,))\n",
    "    sentence_vectors.append(v)\n",
    "v[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9625ca6c6c76404fa612326f3da39156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='progress bar', max=4938, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "he spoke broken English so I couldn't really understand him but when I complained they informed me that the chips they give you are STARTER chips just to get you going which is why when I won I was only given $5 instead of $10...yeah that makes sense.....We did not get a chance to eat at the buffet due to incredibly long lines which btw you have a 3 hr time frame to eat else your free credit is worthless and their insistence that we charge everything to the room.\n",
      "I'm by far not a regular but their staff always makes you feel like you are every time you go in.\n",
      "The whole bathroom was quite large which made getting ready for the day so easy.\n",
      "All in all, not a very good first-time restaurant experience...none of us plan to go back again...just doesn't live up to the hype.\n",
      "I like little touches like that seem like a gimmick but to a little boy without a high chair it's a big smile and it takes such little effort for the cook (I used to be a cook) or the server to make a plate look good.\n",
      "I wanted to dine  in, so my food would be fresh and hot, \n",
      "When we arrived we wasn't greeted properly, maybe they didn't know any better, but that was our first time at their restaurant.I am A very  bold liberal person, in which,  I feel every race creed and color should be treated equally.\n",
      "The water shows were nice, a-little short, but wish they had them more often and also they need to start telling people when the show starts they need to sit down in the font, I mean there were like 3 people constantly standing up and recording the show.\n",
      "Menu options for food is a little lacking for lunch, but they do have breakfast options which I would like to come back and try, especially since I believe their bread will be even more fresh at that moment!\n",
      "Fun atmosphere,  but the food snd service needs big time work or soon the \"next\" place will open and the flock of happy hour parties will be somewhere else.\n",
      "At this point they were now closed so no one was answering when I called, I really wasn't excited to be in pain another day because they can't get their stuff together so I was having to leave messages for the on call docs to make sure they don't just leave for the day without sending the medication over like they said they would.\n"
     ]
    }
   ],
   "source": [
    "# similarity matrix\n",
    "from sklearn.metrics.pairwise import *\n",
    "import networkx as nx\n",
    "length = len(sentences)- 170000\n",
    "sim_mat = np.zeros([length, length])\n",
    "# initialize the matrix with cosine similarity scores\n",
    "for i in tqdm(range(length), desc = 'progress bar', leave=True):\n",
    "    for j in range(length):\n",
    "        if i != j:\n",
    "            sim_mat[i][j] = cosine_similarity(sentence_vectors[i].reshape(1,100), \n",
    "                                              sentence_vectors[j].reshape(1,100))[0,0]\n",
    "\n",
    "#convert the similarity matrix sim_mat into a graph\n",
    "\n",
    "nx_graph = nx.from_numpy_array(sim_mat)\n",
    "scores = nx.pagerank(nx_graph)\n",
    "\n",
    "# extract the top N sentences based on their rankings for summary generation\n",
    "ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences[:4938])), reverse=True)\n",
    "# Extract top 10 sentences as the summary\n",
    "for i in range(10):\n",
    "  print(ranked_sentences[i][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
